{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "moNmVfuvnImW",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torchtext import data\n",
    "from torchtext import datasets\n",
    "import time\n",
    "import random\n",
    "\n",
    "torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "GSRL42Qgy8I8"
   },
   "source": [
    "## General Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OvW1RgfepCBq"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "RANDOM_SEED = 123\n",
    "torch.manual_seed(RANDOM_SEED)\n",
    "\n",
    "VOCABULARY_SIZE = 20000\n",
    "LEARNING_RATE = 1e-4\n",
    "BATCH_SIZE = 64\n",
    "NUM_EPOCHS = 25\n",
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(DEVICE)\n",
    "EMBEDDING_DIM = 128\n",
    "HIDDEN_DIM = 256\n",
    "OUTPUT_DIM = 1\n",
    "\n",
    "PATH = 'best_model.pth' # PATH to save and load model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mQMmKUEisW4W"
   },
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "id": "WZ_4jiHVnMxN",
    "outputId": "dfa51c04-4845-44c3-f50b-d36d41f132b8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num Train: 20000\n",
      "Num Valid: 5000\n",
      "Num Test: 25000\n"
     ]
    }
   ],
   "source": [
    "TEXT = data.Field(tokenize='spacy',\n",
    "                  include_lengths=True) \n",
    "LABEL = data.LabelField(dtype=torch.float)\n",
    "train_data, test_data = datasets.IMDB.splits(TEXT, LABEL)\n",
    "train_data, valid_data = train_data.split(random_state=random.seed(RANDOM_SEED),\n",
    "                                          split_ratio=0.8)\n",
    "\n",
    "print(f'Num Train: {len(train_data)}')\n",
    "print(f'Num Valid: {len(valid_data)}')\n",
    "print(f'Num Test: {len(test_data)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "e8uNrjdtn4A8",
    "outputId": "6cf499d7-7722-4da0-8576-ee0f218cc6e3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary size: 20002\n",
      "Number of classes: 2\n"
     ]
    }
   ],
   "source": [
    "TEXT.build_vocab(train_data,\n",
    "                 max_size=VOCABULARY_SIZE,\n",
    "                 vectors='glove.6B.100d',\n",
    "                 unk_init=torch.Tensor.normal_)\n",
    "LABEL.build_vocab(train_data)\n",
    "\n",
    "print(f'Vocabulary size: {len(TEXT.vocab)}')\n",
    "print(f'Number of classes: {len(LABEL.vocab)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "i7JiHR1stHNF"
   },
   "outputs": [],
   "source": [
    "train_loader, valid_loader, test_loader = data.BucketIterator.splits(\n",
    "    (train_data, valid_data, test_data), \n",
    "    batch_size=BATCH_SIZE,\n",
    "    sort_within_batch=True, \n",
    "    device=DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "colab_type": "code",
    "id": "y8SP_FccutT0",
    "outputId": "fe33763a-4560-4dee-adee-31cc6c48b0b2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train\n",
      "Text matrix size: torch.Size([132, 64])\n",
      "Target vector size: torch.Size([64])\n",
      "\n",
      "Valid:\n",
      "Text matrix size: torch.Size([53, 64])\n",
      "Target vector size: torch.Size([64])\n",
      "\n",
      "Test:\n",
      "Text matrix size: torch.Size([36, 64])\n",
      "Target vector size: torch.Size([64])\n"
     ]
    }
   ],
   "source": [
    "print('Train')\n",
    "for batch in train_loader:\n",
    "    print(f'Text matrix size: {batch.text[0].size()}')\n",
    "    print(f'Target vector size: {batch.label.size()}')\n",
    "    break\n",
    "    \n",
    "print('\\nValid:')\n",
    "for batch in valid_loader:\n",
    "    print(f'Text matrix size: {batch.text[0].size()}')\n",
    "    print(f'Target vector size: {batch.label.size()}')\n",
    "    break\n",
    "    \n",
    "print('\\nTest:')\n",
    "for batch in test_loader:\n",
    "    print(f'Text matrix size: {batch.text[0].size()}')\n",
    "    print(f'Target vector size: {batch.label.size()}')\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "G_grdW3pxCzz"
   },
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nQIUm5EjxFNa"
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class RNN(nn.Module):\n",
    "    def __init__(self, input_dim, embedding_dim, hidden_dim, output_dim):\n",
    "        super(RNN,self).__init__()\n",
    "        self.embedding = nn.Embedding(input_dim,embedding_dim)\n",
    "        self.encoder = nn.GRU(input_size=embedding_dim,\n",
    "                              hidden_size=hidden_dim,\n",
    "                              num_layers=2)\n",
    "        self.pridictor = nn.Linear(hidden_dim,output_dim)\n",
    "        \n",
    "    def forward(self, text):\n",
    "        output, hidden = self.encoder(self.embedding(text))\n",
    "        preds = self.pridictor(hidden[-1])\n",
    "        return preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Ik3NF3faxFmZ"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RNN(\n",
      "  (embedding): Embedding(20002, 128)\n",
      "  (encoder): GRU(128, 256, num_layers=2)\n",
      "  (pridictor): Linear(in_features=256, out_features=1, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "INPUT_DIM = len(TEXT.vocab)\n",
    "\n",
    "torch.manual_seed(RANDOM_SEED)\n",
    "model = RNN(INPUT_DIM, EMBEDDING_DIM, HIDDEN_DIM, OUTPUT_DIM)\n",
    "model = model.to(DEVICE)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Lv9Ny9di6VcI"
   },
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7lRusB3dF80X"
   },
   "outputs": [],
   "source": [
    "def train_val(model,optimizer,criterion,train_loader, valid_loader, epochs, path):\n",
    "    since = time.time()\n",
    "    min_val_loss = 1e10\n",
    "    for epoch in range(epochs):\n",
    "        train_loss=0.0\n",
    "        val_loss=0.0\n",
    "        val_acc = 0.0\n",
    "        \n",
    "        # trainning\n",
    "        model.train()\n",
    "        for idx, batch in enumerate(train_loader):\n",
    "            optimizer.zero_grad()\n",
    "            inputs, labels=batch.text, batch.label\n",
    "            # print(inputs[0].size())\n",
    "            # print(inputs[1].size())\n",
    "            inputs=inputs[0].to(DEVICE)\n",
    "            labels=labels.to(DEVICE)\n",
    "            outputs = model(inputs).squeeze()\n",
    "            # print(outputs.size())\n",
    "            # print(labels.size())\n",
    "            loss = criterion(outputs,labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            train_loss += loss.data.item()\n",
    "            # print(batch.text[0].size(0))\n",
    "        train_loss /= len(train_loader)\n",
    "        # print(len(train_loader))\n",
    "        print(f\"epoch: {epoch+1}: train loss:{train_loss}\")\n",
    "        \n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            for val_idx, val_batch in enumerate(valid_loader):\n",
    "                val_inputs, val_labels=val_batch.text, val_batch.label\n",
    "                val_inputs = val_inputs[0].to(DEVICE)\n",
    "                val_labels = val_labels.to(DEVICE)\n",
    "                val_outputs = model(val_inputs).squeeze()\n",
    "                val_outputs_acc = torch.sigmoid(val_outputs) > 0.5\n",
    "                val_acc+=torch.sum(val_outputs_acc==val_labels)\n",
    "                loss = criterion(val_outputs,val_labels)\n",
    "                val_loss += loss.data.item()\n",
    "        val_loss /= len(valid_loader)\n",
    "        val_acc /= len(valid_data)\n",
    "        print(f\"epoch: {epoch+1}: val loss:{val_loss} val acc:{val_acc}\")\n",
    "\n",
    "        if val_loss<min_val_loss:\n",
    "            min_val_loss = val_loss\n",
    "            torch.save(model.state_dict(),path)\n",
    "            print('model saved!')\n",
    "\n",
    "        \n",
    "    time_elapsed = time.time() - since\n",
    "    print('\\nTraining complete in {:.0f}m {:.0f}s'.format(\n",
    "        time_elapsed // 60, time_elapsed % 60))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1: train loss:0.6835421677976371\n",
      "epoch: 1: val loss:0.6477129217944567 val acc:0.626800000667572\n",
      "model saved!\n",
      "epoch: 2: train loss:0.5965642642479735\n",
      "epoch: 2: val loss:0.5897364616394043 val acc:0.7053999900817871\n",
      "model saved!\n",
      "epoch: 3: train loss:0.5738197668863181\n",
      "epoch: 3: val loss:0.6299606252320206 val acc:0.6444000005722046\n",
      "epoch: 4: train loss:0.5632631084599053\n",
      "epoch: 4: val loss:0.513651861042916 val acc:0.7563999891281128\n",
      "model saved!\n",
      "epoch: 5: train loss:0.475137968413746\n",
      "epoch: 5: val loss:0.4993498132953161 val acc:0.7689999938011169\n",
      "model saved!\n",
      "epoch: 6: train loss:0.4298770973286309\n",
      "epoch: 6: val loss:0.43247136926349206 val acc:0.8050000071525574\n",
      "model saved!\n",
      "epoch: 7: train loss:0.38874159958035037\n",
      "epoch: 7: val loss:0.45439645006686824 val acc:0.7863999605178833\n",
      "epoch: 8: train loss:0.35756104275250966\n",
      "epoch: 8: val loss:0.38473035074487516 val acc:0.8267999887466431\n",
      "model saved!\n",
      "epoch: 9: train loss:0.32218029333379705\n",
      "epoch: 9: val loss:0.35757766758339316 val acc:0.8443999886512756\n",
      "model saved!\n",
      "epoch: 10: train loss:0.2977005910045042\n",
      "epoch: 10: val loss:0.34365216086182415 val acc:0.8503999710083008\n",
      "model saved!\n",
      "epoch: 11: train loss:0.2807763788265923\n",
      "epoch: 11: val loss:0.3383618664892414 val acc:0.8513999581336975\n",
      "model saved!\n",
      "epoch: 12: train loss:0.26215628458383367\n",
      "epoch: 12: val loss:0.3974632217159754 val acc:0.8279999494552612\n",
      "epoch: 13: train loss:0.2547254409081639\n",
      "epoch: 13: val loss:0.3307822105250781 val acc:0.8605999946594238\n",
      "model saved!\n",
      "epoch: 14: train loss:0.22359525651548998\n",
      "epoch: 14: val loss:0.31648961086816424 val acc:0.8689999580383301\n",
      "model saved!\n",
      "epoch: 15: train loss:0.21599010680430233\n",
      "epoch: 15: val loss:0.3151600787156745 val acc:0.8691999912261963\n",
      "model saved!\n",
      "epoch: 16: train loss:0.2067132857851327\n",
      "epoch: 16: val loss:0.3092510766243633 val acc:0.8745999932289124\n",
      "model saved!\n",
      "epoch: 17: train loss:0.17941649543782012\n",
      "epoch: 17: val loss:0.38717115302629107 val acc:0.854200005531311\n",
      "epoch: 18: train loss:0.16824390201237255\n",
      "epoch: 18: val loss:0.321413759189316 val acc:0.8761999607086182\n",
      "epoch: 19: train loss:0.1655416112785903\n",
      "epoch: 19: val loss:0.33807599902907504 val acc:0.8643999695777893\n",
      "epoch: 20: train loss:0.14640190080403329\n",
      "epoch: 20: val loss:0.339829983967769 val acc:0.8777999877929688\n",
      "epoch: 21: train loss:0.13006607019387115\n",
      "epoch: 21: val loss:0.33448592903493324 val acc:0.8789999485015869\n",
      "epoch: 22: train loss:0.12451508696586751\n",
      "epoch: 22: val loss:0.35226176471649845 val acc:0.8807999491691589\n",
      "epoch: 23: train loss:0.10731851908500298\n",
      "epoch: 23: val loss:0.3588738082141816 val acc:0.8799999952316284\n",
      "epoch: 24: train loss:0.10749068094221072\n",
      "epoch: 24: val loss:0.3803804492271399 val acc:0.8761999607086182\n",
      "epoch: 25: train loss:0.09847015457840773\n",
      "epoch: 25: val loss:0.3767201617548737 val acc:0.8797999620437622\n",
      "\n",
      "Training complete in 39m 57s\n"
     ]
    }
   ],
   "source": [
    "train_val(model,optimizer,criterion,train_loader, valid_loader, NUM_EPOCHS, PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## testing\n"
   ],
   "execution_count": 10
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "def test(model, test_loader):\n",
    "    acc = 0.0\n",
    "    test_loss = 0.0\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for idx, batch in enumerate(test_loader):\n",
    "            inputs, labels=batch.text, batch.label\n",
    "            inputs = inputs[0].to(DEVICE)\n",
    "            labels = labels.to(DEVICE)\n",
    "            outputs = model(inputs).squeeze()\n",
    "            loss = criterion(outputs,labels)\n",
    "            test_loss += loss.data.item()\n",
    "            outputs = torch.sigmoid(outputs)>0.5\n",
    "            acc+=torch.sum(outputs==labels)\n",
    "    acc /= len(test_data)\n",
    "    test_loss /= len(test_loader)\n",
    "    print(f\"test loss: {test_loss}: test acc:{acc}\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test loss: 0.3273980164962351: test acc:0.8684399724006653\n"
     ]
    }
   ],
   "source": [
    "model = RNN(INPUT_DIM, EMBEDDING_DIM, HIDDEN_DIM, OUTPUT_DIM)\n",
    "model = model.to(DEVICE)\n",
    "model.load_state_dict(torch.load(PATH))\n",
    "test(model, test_loader)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "rnn_lstm_packed_imdb.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "name": "lab2",
   "language": "python",
   "display_name": "Lab2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}